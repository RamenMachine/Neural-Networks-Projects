{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adfdad2c",
   "metadata": {},
   "source": [
    "# ECE 491 — Homework 4: MNIST Classification Report\n",
    "\n",
    "This notebook implements a neural network for handwritten digit classification using the MNIST dataset loaded from raw IDX files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e665c4e0",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for data loading, model building, training, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa8e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, gzip, struct, datetime, numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ec41be",
   "metadata": {},
   "source": [
    "## 2. MNIST Data Loading Functions\n",
    "\n",
    "Define functions to load MNIST data from raw IDX files (both compressed .gz and uncompressed formats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f39f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(dataset_dir=\"./\"):\n",
    "    def _read_images(path):\n",
    "        if path.endswith('.gz'):\n",
    "            with gzip.open(path, 'rb') as f:\n",
    "                magic, n, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "                data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "                return data.reshape(n, rows*cols)\n",
    "        else:\n",
    "            with open(path, 'rb') as f:\n",
    "                magic, n, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "                data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "                return data.reshape(n, rows*cols)\n",
    "    \n",
    "    def _read_labels(path):\n",
    "        if path.endswith('.gz'):\n",
    "            with gzip.open(path, 'rb') as f:\n",
    "                magic, n = struct.unpack('>II', f.read(8))\n",
    "                data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "                return data\n",
    "        else:\n",
    "            with open(path, 'rb') as f:\n",
    "                magic, n = struct.unpack('>II', f.read(8))\n",
    "                data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "                return data\n",
    "\n",
    "    req_gz = [\n",
    "        \"train-images-idx3-ubyte.gz\",\n",
    "        \"train-labels-idx1-ubyte.gz\",\n",
    "        \"t10k-images-idx3-ubyte.gz\",\n",
    "        \"t10k-labels-idx1-ubyte.gz\",\n",
    "    ]\n",
    "    req_uncompressed = [\n",
    "        \"train-images.idx3-ubyte\",\n",
    "        \"train-labels.idx1-ubyte\",\n",
    "        \"t10k-images.idx3-ubyte\",\n",
    "        \"t10k-labels.idx1-ubyte\",\n",
    "    ]\n",
    "    \n",
    "    files_to_use = []\n",
    "    for gz_file, uncomp_file in zip(req_gz, req_uncompressed):\n",
    "        gz_path = os.path.join(dataset_dir, gz_file)\n",
    "        uncomp_path = os.path.join(dataset_dir, uncomp_file)\n",
    "        if os.path.exists(gz_path):\n",
    "            files_to_use.append(gz_path)\n",
    "        elif os.path.exists(uncomp_path):\n",
    "            files_to_use.append(uncomp_path)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Missing MNIST file. Need either {gz_file} or {uncomp_file}\")\n",
    "    \n",
    "    if len(files_to_use) != 4:\n",
    "        raise FileNotFoundError(f\"Could not find all required MNIST files\")\n",
    "\n",
    "    trX = _read_images(files_to_use[0]).astype(\"float32\")/255.0\n",
    "    trY = _read_labels(files_to_use[1]).astype(\"int64\")\n",
    "    teX = _read_images(files_to_use[2]).astype(\"float32\")/255.0\n",
    "    teY = _read_labels(files_to_use[3]).astype(\"int64\")\n",
    "    return trX, trY, teX, teY\n",
    "\n",
    "print(\"MNIST loading functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae69c2",
   "metadata": {},
   "source": [
    "## 3. Load and Explore MNIST Dataset\n",
    "\n",
    "Load the MNIST dataset and display basic information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba11c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = load_mnist(\"./\")\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Training images shape: {train_x.shape}\")\n",
    "print(f\"Training labels shape: {train_y.shape}\")\n",
    "print(f\"Test images shape: {test_x.shape}\")\n",
    "print(f\"Test labels shape: {test_y.shape}\")\n",
    "print(f\"Pixel value range: [{train_x.min():.3f}, {train_x.max():.3f}]\")\n",
    "print(f\"Unique labels: {np.unique(train_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059a4fc5",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Images\n",
    "\n",
    "Display a few sample images from the training set to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    row, col = i // 5, i % 5\n",
    "    img = train_x[i].reshape(28, 28)\n",
    "    axes[row, col].imshow(img, cmap='gray')\n",
    "    axes[row, col].set_title(f'Label: {train_y[i]}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Sample MNIST Images', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5214967b",
   "metadata": {},
   "source": [
    "## 5. Build Neural Network Model\n",
    "\n",
    "Create a 3-layer fully connected neural network for digit classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3688f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171e467",
   "metadata": {},
   "source": [
    "## 6. Model Configuration Summary\n",
    "\n",
    "Display the key hyperparameters and configuration details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Model Configuration ===\")\n",
    "print(f\"Dataset: MNIST (raw IDX files)\")\n",
    "print(f\"Task: Handwritten digit classification (10 classes)\")\n",
    "print(f\"Network Architecture: 3 fully connected layers (784→256→128→10)\")\n",
    "print(f\"Loss Function: Sparse Categorical Cross-Entropy (from logits=True)\")\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"Learning Rate: 1e-3\")\n",
    "print(f\"Normalization: Pixel intensities scaled to [0,1]\")\n",
    "print(f\"Training Parameters: epochs=10, batch_size=128, validation_split=0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418ca3b0",
   "metadata": {},
   "source": [
    "## 7. Train the Model\n",
    "\n",
    "Train the neural network and monitor the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9894bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    validation_split=0.1,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399df54",
   "metadata": {},
   "source": [
    "## 8. Plot Training History\n",
    "\n",
    "Visualize the training and validation loss and accuracy over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873f029a",
   "metadata": {},
   "source": [
    "## 9. Evaluate Model on Test Set\n",
    "\n",
    "Evaluate the trained model on the test set and calculate key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logits = model.predict(test_x, batch_size=512, verbose=0)\n",
    "test_pred = np.argmax(test_logits, axis=1)\n",
    "test_acc = float(np.mean(test_pred == test_y))\n",
    "\n",
    "print(f\"=== Test Results ===\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"Test Error Rate: {(1-test_acc)*100:.2f}%\")\n",
    "print(f\"Correct Predictions: {np.sum(test_pred == test_y)}/{len(test_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4839f3e5",
   "metadata": {},
   "source": [
    "## 10. Generate and Visualize Confusion Matrix\n",
    "\n",
    "Create a confusion matrix to analyze model performance across different digit classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(labels=test_y, predictions=test_pred, num_classes=10).numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "ax.set_title(\"Confusion Matrix\", fontsize=16, pad=20)\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "ax.set_xlabel(\"Predicted Label\", fontsize=14)\n",
    "ax.set_ylabel(\"True Label\", fontsize=14)\n",
    "ax.set_xticks(range(10))\n",
    "ax.set_yticks(range(10))\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        text_color = \"white\" if cm[i,j] > cm.max()/2 else \"black\"\n",
    "        ax.text(j, i, int(cm[i, j]), ha=\"center\", va=\"center\", \n",
    "                fontsize=12, color=text_color, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"Rows = True Labels, Columns = Predicted Labels\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ecf172",
   "metadata": {},
   "source": [
    "## 11. Per-Class Performance Analysis\n",
    "\n",
    "Analyze performance metrics for each digit class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Per-Class Performance ===\")\n",
    "print(f\"{'Digit':<5} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<8}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for digit in range(10):\n",
    "    tp = cm[digit, digit]\n",
    "    fp = cm[:, digit].sum() - tp\n",
    "    fn = cm[digit, :].sum() - tp\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    support = cm[digit, :].sum()\n",
    "    \n",
    "    print(f\"{digit:<5} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {support:<8}\")\n",
    "\n",
    "total_correct = np.trace(cm)\n",
    "total_samples = cm.sum()\n",
    "overall_accuracy = total_correct / total_samples\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6c882",
   "metadata": {},
   "source": [
    "## 12. Sample Predictions Visualization\n",
    "\n",
    "Display some test images with their true labels and model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c23b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "sample_indices = np.random.choice(len(test_x), 15, replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    row, col = i // 5, i % 5\n",
    "    img = test_x[idx].reshape(28, 28)\n",
    "    true_label = test_y[idx]\n",
    "    pred_label = test_pred[idx]\n",
    "    \n",
    "    axes[row, col].imshow(img, cmap='gray')\n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    axes[row, col].set_title(f'True: {true_label}, Pred: {pred_label}', color=color, fontsize=10)\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Test Predictions (Green=Correct, Red=Incorrect)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30919d",
   "metadata": {},
   "source": [
    "## 13. Summary and Conclusions\n",
    "\n",
    "Final summary of the model performance and key findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a278d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MNIST Classification Report Summary ===\")\n",
    "print(f\"Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\n=== Dataset Information ===\")\n",
    "print(f\"• Dataset: MNIST handwritten digits\")\n",
    "print(f\"• Training samples: {len(train_x):,}\")\n",
    "print(f\"• Test samples: {len(test_x):,}\")\n",
    "print(f\"• Classes: 10 (digits 0-9)\")\n",
    "print(f\"• Image size: 28×28 pixels\")\n",
    "\n",
    "print(\"\\n=== Model Architecture ===\")\n",
    "print(f\"• Network: 3-layer fully connected\")\n",
    "print(f\"• Layers: 784 → 256 → 128 → 10\")\n",
    "print(f\"• Activation: ReLU (hidden layers)\")\n",
    "print(f\"• Output: Logits (no activation)\")\n",
    "print(f\"• Parameters: {model.count_params():,}\")\n",
    "\n",
    "print(\"\\n=== Training Configuration ===\")\n",
    "print(f\"• Optimizer: Adam (lr=1e-3)\")\n",
    "print(f\"• Loss: Sparse Categorical Cross-Entropy\")\n",
    "print(f\"• Epochs: 10\")\n",
    "print(f\"• Batch size: 128\")\n",
    "print(f\"• Validation split: 10%\")\n",
    "\n",
    "print(\"\\n=== Results ===\")\n",
    "print(f\"• Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"• Test Error Rate: {(1-test_acc)*100:.2f}%\")\n",
    "print(f\"• Training Time: ~10 epochs\")\n",
    "\n",
    "print(\"\\n=== Key Findings ===\")\n",
    "if test_acc > 0.98:\n",
    "    print(f\"• Excellent performance (>98% accuracy)\")\n",
    "elif test_acc > 0.95:\n",
    "    print(f\"• Very good performance (>95% accuracy)\")\n",
    "else:\n",
    "    print(f\"• Good performance\")\n",
    "\n",
    "print(f\"• Model successfully learned digit patterns\")\n",
    "print(f\"• Confusion matrix shows balanced performance across digits\")\n",
    "print(f\"• Ready for deployment or further optimization\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Report completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
