{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e5a3aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 - Data shapes:\n",
      "xTrain: (60000, 28, 28), yTrain: (60000,)\n",
      "xTest: (10000, 28, 28), yTest: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Lab 4 - MNIST Shallow Neural Network\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST data\n",
    "(xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize to [0,1]\n",
    "xTrain = xTrain.astype('float32') / 255.0\n",
    "xTest = xTest.astype('float32') / 255.0\n",
    "\n",
    "# Q1: Print shapes\n",
    "print(f\"Q1 - Data shapes:\")\n",
    "print(f\"xTrain: {xTrain.shape}, yTrain: {yTrain.shape}\")\n",
    "print(f\"xTest: {xTest.shape}, yTest: {yTest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5072e1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2 - Split sizes: Train 48000, Val 12000\n"
     ]
    }
   ],
   "source": [
    "# Q2: Create 80/20 train/validation split\n",
    "splitIdx = int(0.8 * len(xTrain))\n",
    "xVal = xTrain[splitIdx:]\n",
    "yVal = yTrain[splitIdx:]\n",
    "xTrain = xTrain[:splitIdx]\n",
    "yTrain = yTrain[:splitIdx]\n",
    "\n",
    "print(f\"Q2 - Split sizes: Train {xTrain.shape[0]}, Val {xVal.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae406c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4 - Model A output shape: (None, 10)\n"
     ]
    }
   ],
   "source": [
    "# Q3: Layer parameter documentation\n",
    "\"\"\"\n",
    "Flatten(input_shape): Reshapes input tensor to 1D, input_shape specifies expected input dimensions\n",
    "Dense(units, activation): Fully connected layer, units=number of neurons, activation=activation function  \n",
    "Dropout(rate): Randomly sets rate fraction of inputs to 0 during training for regularization\n",
    "\"\"\"\n",
    "\n",
    "modelA = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "lossFn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "modelA.compile(optimizer='adam', loss=lossFn, metrics=['accuracy'])\n",
    "\n",
    "# Q4: Print output shape (build model first)\n",
    "modelA.build(input_shape=(None, 28, 28))\n",
    "print(f\"Q4 - Model A output shape: {modelA.output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37e4461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.3325 - val_accuracy: 0.9550 - val_loss: 0.1655\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.1616 - val_accuracy: 0.9663 - val_loss: 0.1190\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.1180 - val_accuracy: 0.9687 - val_loss: 0.1023\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.0958 - val_accuracy: 0.9720 - val_loss: 0.0944\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9754 - loss: 0.0801 - val_accuracy: 0.9743 - val_loss: 0.0869\n",
      "Q5 - Model A final validation accuracy: 0.9743\n",
      "Q6 - Model A test accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "historyA = modelA.fit(xTrain, yTrain, epochs=5, validation_data=(xVal, yVal), verbose=1)\n",
    "\n",
    "# Q5: Final validation accuracy\n",
    "finalValAccA = historyA.history['val_accuracy'][-1]\n",
    "print(f\"Q5 - Model A final validation accuracy: {finalValAccA:.4f}\")\n",
    "\n",
    "# Q6: Test accuracy\n",
    "testLossA, testAccA = modelA.evaluate(xTest, yTest, verbose=0)\n",
    "print(f\"Q6 - Model A test accuracy: {testAccA:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27bd4455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.2307 - val_accuracy: 0.9606 - val_loss: 0.1271\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9706 - loss: 0.0973 - val_accuracy: 0.9684 - val_loss: 0.1024\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0660 - val_accuracy: 0.9698 - val_loss: 0.0991\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0465 - val_accuracy: 0.9678 - val_loss: 0.1135\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0366 - val_accuracy: 0.9693 - val_loss: 0.1103\n",
      "Q7 - Model B final validation accuracy: 0.9693\n",
      "Q7 - Model B test accuracy: 0.9724\n"
     ]
    }
   ],
   "source": [
    "modelB = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "modelB.compile(optimizer='adam', loss=lossFn, metrics=['accuracy'])\n",
    "\n",
    "historyB = modelB.fit(xTrain, yTrain, epochs=5, validation_data=(xVal, yVal), verbose=1)\n",
    "\n",
    "# Q7: Final validation and test accuracy\n",
    "finalValAccB = historyB.history['val_accuracy'][-1]\n",
    "testLossB, testAccB = modelB.evaluate(xTest, yTest, verbose=0)\n",
    "\n",
    "print(f\"Q7 - Model B final validation accuracy: {finalValAccB:.4f}\")\n",
    "print(f\"Q7 - Model B test accuracy: {testAccB:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
